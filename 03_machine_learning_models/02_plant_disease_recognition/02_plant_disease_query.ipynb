{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Recognition Model: Inference Notebook\n",
    "\n",
    "Name: Zihan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - (One-Time Utility) Create Class Map File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# # 1. 将你从Colab复制的字典粘贴在这里\n",
    "# # 我们需要 import numpy as np 才能让Python理解 np.int64() 是什么\n",
    "# original_map = {0: np.int64(0), 1: np.int64(5), 2: np.int64(6), 3: np.int64(7), 4: np.int64(9), 5: np.int64(10), 6: np.int64(13), 7: np.int64(18), 8: np.int64(22), 9: np.int64(31), 10: np.int64(34), 11: np.int64(38), 12: np.int64(49), 13: np.int64(52), 14: np.int64(56), 15: np.int64(61), 16: np.int64(67), 17: np.int64(75), 18: np.int64(82), 19: np.int64(83), 20: np.int64(92), 21: np.int64(98)}\n",
    "\n",
    "# # 2. 清理数据，将其转换为纯粹的Python类型\n",
    "# #   - 将key转换为字符串 (JSON标准)\n",
    "# #   - 将value从np.int64转换为普通的int\n",
    "# cleaned_map = {str(k): int(v) for k, v in original_map.items()}\n",
    "\n",
    "\n",
    "# # 3. 定义输出文件名\n",
    "# output_filename = \"class_map.json\"\n",
    "\n",
    "# # 4. 使用json库将清理后的字典保存为格式正确的文件\n",
    "# with open(output_filename, 'w') as f:\n",
    "#     json.dump(cleaned_map, f, indent=4)\n",
    "\n",
    "# print(f\"✅ 成功创建了格式完全正确的 '{output_filename}' 文件！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Environment Configuration & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "脚本/Notebook所在目录: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\n",
      "模型文件预期路径: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\\model.pth\n",
      "映射文件预期路径: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\\class_map.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "import timm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# 忽略一些不影响结果的警告信息\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====================================================================\n",
    "# 1. 配置信息 (Configuration - 使用你提供的最佳实践)\n",
    "# ====================================================================\n",
    "\n",
    "# --- 动态获取当前Notebook或脚本所在的目录 (你提供的代码) ---\n",
    "# 这能确保我们总能从文件所在位置开始寻找，无论当前工作目录是什么\n",
    "NOTEBOOK_DIR = Path(__file__).parent if \"__file__\" in globals() else Path().resolve()\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    \"\"\"\n",
    "    存放所有配置信息，方便统一修改。\n",
    "    \"\"\"\n",
    "    # --- 路径配置 (现在基于NOTEBOOK_DIR，非常稳健) ---\n",
    "    # 训练好的模型权重文件路径\n",
    "    MODEL_PATH = NOTEBOOK_DIR / \"model.pth\"\n",
    "    # 索引 -> ID 的映射文件路径\n",
    "    CLASS_MAP_PATH = NOTEBOOK_DIR / \"class_map.json\"\n",
    "    \n",
    "    # --- 模型配置 (必须与训练时完全一致) ---\n",
    "    MODEL_NAME = 'swin_base_patch4_window7_224.ms_in1k'\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    # --- 推理设备 ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 打印出最终的绝对路径以供检查 ---\n",
    "print(f\"脚本/Notebook所在目录: {NOTEBOOK_DIR}\")\n",
    "print(f\"模型文件预期路径: {CFG.MODEL_PATH}\")\n",
    "print(f\"映射文件预期路径: {CFG.CLASS_MAP_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Load Class Mapping Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 2. 加载“翻译词典”\n",
    "# ====================================================================\n",
    "def load_class_map(json_path):\n",
    "    \"\"\"从JSON文件加载 索引 -> ID 的映射字典\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            idx_to_label = json.load(f)\n",
    "            # JSON加载的key默认是字符串，我们需要将其转为整数以匹配PyTorch的输出\n",
    "            idx_to_label = {int(k): v for k, v in idx_to_label.items()}\n",
    "        print(\"✅ 翻译词典加载成功。\")\n",
    "        return idx_to_label\n",
    "    except FileNotFoundError:\n",
    "        print(f\"🛑 错误: 映射文件未找到于 '{json_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"🛑 错误: '{json_path}' 不是一个有效的JSON文件。\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 3. 加载训练好的模型\n",
    "# ====================================================================\n",
    "def load_model(model_name, num_classes, model_path, device):\n",
    "    \"\"\"加载模型架构并载入训练好的权重\"\"\"\n",
    "    try:\n",
    "        # pretrained=False, 因为我们要加载自己的本地权重\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "        # 使用 map_location=device 确保无论模型在GPU还是CPU上训练，都能在当前设备正确加载\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval() # 切换到评估模式，这非常重要！\n",
    "        print(\"✅ 模型加载成功。\")\n",
    "        return model\n",
    "    except FileNotFoundError:\n",
    "        print(f\"🛑 错误: 模型文件未找到于 '{model_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"🛑 加载模型时发生未知错误: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 4. 定义图像预处理流程\n",
    "# ====================================================================\n",
    "# 推理时使用的图像转换，必须与训练时的验证/测试集转换完全一致\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Define Image Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 5. 核心预测函数\n",
    "# ====================================================================\n",
    "def predict_top3(model, image_path, transforms, idx_to_label_map, device):\n",
    "    \"\"\"对单张图片进行Top-3预测，只输出ID和概率\"\"\"\n",
    "    try:\n",
    "        # 加载并预处理图片\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        # .unsqueeze(0) 是为了增加一个batch维度，因为模型需要 [B, C, H, W] 形状的输入\n",
    "        image_tensor = transforms(image).unsqueeze(0).to(device)\n",
    "    except FileNotFoundError:\n",
    "        return f\"🛑 错误: 图片文件未找到于 '{image_path}'\"\n",
    "    except Exception as e:\n",
    "        return f\"🛑 处理图片时发生错误: {e}\"\n",
    "\n",
    "    # 关闭梯度计算，能加速推理并节省显存\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "\n",
    "    # 应用Softmax函数将logits转换为概率\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # 获取概率最高的3个值和它们对应的索引\n",
    "    top3_probs, top3_indices = torch.topk(probabilities, 3, dim=1)\n",
    "\n",
    "    # 将Tensor从GPU移动到CPU，并转换为Numpy数组以便处理\n",
    "    top3_probs = top3_probs.squeeze().cpu().numpy()\n",
    "    top3_indices = top3_indices.squeeze().cpu().numpy()\n",
    "    \n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        class_idx = top3_indices[i]\n",
    "        # **关键翻译步骤**：将模型的内部索引(class_idx)转换为真实ID(class_id)\n",
    "        class_id = idx_to_label_map[class_idx]\n",
    "        prob = top3_probs[i]\n",
    "        \n",
    "        results.append({\n",
    "            \"predicted_id\": int(class_id), # 确保ID是整数\n",
    "            \"probability\": f\"{prob:.2%}\"   # 格式化为百分比字符串\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Execute Inference and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始植物病害识别推理 ---\n",
      "使用设备: cuda\n",
      "\n",
      "[1/3] 正在加载标签映射表...\n",
      "✅ 翻译词典加载成功。\n",
      "\n",
      "[2/3] 正在加载模型...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型加载成功。\n",
      "\n",
      "[3/3] 正在执行预测...\n",
      "\n",
      "==============================\n",
      "--- 预测结果 (Top 3) ---\n",
      "图片: test_images/011d0.jfif\n",
      "==============================\n",
      "病害ID: 0     | 概率: 89.83%\n",
      "病害ID: 31    | 概率: 0.72%\n",
      "病害ID: 22    | 概率: 0.68%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# 6. 主执行入口\n",
    "# ====================================================================\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 开始植物病害识别推理 ---\")\n",
    "    print(f\"使用设备: {CFG.DEVICE}\")\n",
    "    \n",
    "    # 步骤 1: 加载翻译词典\n",
    "    print(\"\\n[1/3] 正在加载标签映射表...\")\n",
    "    idx_to_label = load_class_map(CFG.CLASS_MAP_PATH)\n",
    "    \n",
    "    # 步骤 2: 加载模型\n",
    "    if idx_to_label is not None:\n",
    "        print(\"\\n[2/3] 正在加载模型...\")\n",
    "        # 模型的类别数必须与翻译词典的大小一致\n",
    "        num_classes = len(idx_to_label)\n",
    "        model = load_model(CFG.MODEL_NAME, num_classes, CFG.MODEL_PATH, CFG.DEVICE)\n",
    "    else:\n",
    "        model = None\n",
    "\n",
    "    # 步骤 3: 执行预测\n",
    "    if model is not None:\n",
    "        print(\"\\n[3/3] 正在执行预测...\")\n",
    "        # !! 需要你指定一张本地图片的路径 !!\n",
    "        TEST_IMAGE_PATH = \"test_images/011d0.jfif\" # <--- 在这里修改为你本地的测试图片路径\n",
    "\n",
    "        if Path(TEST_IMAGE_PATH).exists():\n",
    "            top3_predictions = predict_top3(model, TEST_IMAGE_PATH, inference_transforms, idx_to_label, CFG.DEVICE)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"--- 预测结果 (Top 3) ---\")\n",
    "            print(f\"图片: {TEST_IMAGE_PATH}\")\n",
    "            print(\"=\"*30)\n",
    "            for pred in top3_predictions:\n",
    "                print(f\"病害ID: {pred['predicted_id']:<5} | 概率: {pred['probability']}\")\n",
    "        else:\n",
    "            print(f\"🛑 错误: 测试图片 '{TEST_IMAGE_PATH}' 不存在。请修改路径后重试。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
