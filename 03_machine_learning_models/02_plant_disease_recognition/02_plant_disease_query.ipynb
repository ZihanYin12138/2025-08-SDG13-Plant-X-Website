{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Recognition Model: Inference Notebook\n",
    "\n",
    "Name: Zihan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - (One-Time Utility) Create Class Map File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# # 1. å°†ä½ ä»Colabå¤åˆ¶çš„å­—å…¸ç²˜è´´åœ¨è¿™é‡Œ\n",
    "# # æˆ‘ä»¬éœ€è¦ import numpy as np æ‰èƒ½è®©Pythonç†è§£ np.int64() æ˜¯ä»€ä¹ˆ\n",
    "# original_map = {0: np.int64(0), 1: np.int64(5), 2: np.int64(6), 3: np.int64(7), 4: np.int64(9), 5: np.int64(10), 6: np.int64(13), 7: np.int64(18), 8: np.int64(22), 9: np.int64(31), 10: np.int64(34), 11: np.int64(38), 12: np.int64(49), 13: np.int64(52), 14: np.int64(56), 15: np.int64(61), 16: np.int64(67), 17: np.int64(75), 18: np.int64(82), 19: np.int64(83), 20: np.int64(92), 21: np.int64(98)}\n",
    "\n",
    "# # 2. æ¸…ç†æ•°æ®ï¼Œå°†å…¶è½¬æ¢ä¸ºçº¯ç²¹çš„Pythonç±»å‹\n",
    "# #   - å°†keyè½¬æ¢ä¸ºå­—ç¬¦ä¸² (JSONæ ‡å‡†)\n",
    "# #   - å°†valueä»np.int64è½¬æ¢ä¸ºæ™®é€šçš„int\n",
    "# cleaned_map = {str(k): int(v) for k, v in original_map.items()}\n",
    "\n",
    "\n",
    "# # 3. å®šä¹‰è¾“å‡ºæ–‡ä»¶å\n",
    "# output_filename = \"class_map.json\"\n",
    "\n",
    "# # 4. ä½¿ç”¨jsonåº“å°†æ¸…ç†åçš„å­—å…¸ä¿å­˜ä¸ºæ ¼å¼æ­£ç¡®çš„æ–‡ä»¶\n",
    "# with open(output_filename, 'w') as f:\n",
    "#     json.dump(cleaned_map, f, indent=4)\n",
    "\n",
    "# print(f\"âœ… æˆåŠŸåˆ›å»ºäº†æ ¼å¼å®Œå…¨æ­£ç¡®çš„ '{output_filename}' æ–‡ä»¶ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Environment Configuration & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è„šæœ¬/Notebookæ‰€åœ¨ç›®å½•: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\n",
      "æ¨¡å‹æ–‡ä»¶é¢„æœŸè·¯å¾„: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\\model.pth\n",
      "æ˜ å°„æ–‡ä»¶é¢„æœŸè·¯å¾„: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\03_machine_learning_models\\02_plant_disease_recognition\\class_map.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "import timm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# å¿½ç•¥ä¸€äº›ä¸å½±å“ç»“æœçš„è­¦å‘Šä¿¡æ¯\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====================================================================\n",
    "# 1. é…ç½®ä¿¡æ¯ (Configuration - ä½¿ç”¨ä½ æä¾›çš„æœ€ä½³å®è·µ)\n",
    "# ====================================================================\n",
    "\n",
    "# --- åŠ¨æ€è·å–å½“å‰Notebookæˆ–è„šæœ¬æ‰€åœ¨çš„ç›®å½• (ä½ æä¾›çš„ä»£ç ) ---\n",
    "# è¿™èƒ½ç¡®ä¿æˆ‘ä»¬æ€»èƒ½ä»æ–‡ä»¶æ‰€åœ¨ä½ç½®å¼€å§‹å¯»æ‰¾ï¼Œæ— è®ºå½“å‰å·¥ä½œç›®å½•æ˜¯ä»€ä¹ˆ\n",
    "NOTEBOOK_DIR = Path(__file__).parent if \"__file__\" in globals() else Path().resolve()\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    \"\"\"\n",
    "    å­˜æ”¾æ‰€æœ‰é…ç½®ä¿¡æ¯ï¼Œæ–¹ä¾¿ç»Ÿä¸€ä¿®æ”¹ã€‚\n",
    "    \"\"\"\n",
    "    # --- è·¯å¾„é…ç½® (ç°åœ¨åŸºäºNOTEBOOK_DIRï¼Œéå¸¸ç¨³å¥) ---\n",
    "    # è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„\n",
    "    MODEL_PATH = NOTEBOOK_DIR / \"model.pth\"\n",
    "    # ç´¢å¼• -> ID çš„æ˜ å°„æ–‡ä»¶è·¯å¾„\n",
    "    CLASS_MAP_PATH = NOTEBOOK_DIR / \"class_map.json\"\n",
    "    \n",
    "    # --- æ¨¡å‹é…ç½® (å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´) ---\n",
    "    MODEL_NAME = 'swin_base_patch4_window7_224.ms_in1k'\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "    # --- æ¨ç†è®¾å¤‡ ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- æ‰“å°å‡ºæœ€ç»ˆçš„ç»å¯¹è·¯å¾„ä»¥ä¾›æ£€æŸ¥ ---\n",
    "print(f\"è„šæœ¬/Notebookæ‰€åœ¨ç›®å½•: {NOTEBOOK_DIR}\")\n",
    "print(f\"æ¨¡å‹æ–‡ä»¶é¢„æœŸè·¯å¾„: {CFG.MODEL_PATH}\")\n",
    "print(f\"æ˜ å°„æ–‡ä»¶é¢„æœŸè·¯å¾„: {CFG.CLASS_MAP_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Load Class Mapping Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 2. åŠ è½½â€œç¿»è¯‘è¯å…¸â€\n",
    "# ====================================================================\n",
    "def load_class_map(json_path):\n",
    "    \"\"\"ä»JSONæ–‡ä»¶åŠ è½½ ç´¢å¼• -> ID çš„æ˜ å°„å­—å…¸\"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            idx_to_label = json.load(f)\n",
    "            # JSONåŠ è½½çš„keyé»˜è®¤æ˜¯å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬ä¸ºæ•´æ•°ä»¥åŒ¹é…PyTorchçš„è¾“å‡º\n",
    "            idx_to_label = {int(k): v for k, v in idx_to_label.items()}\n",
    "        print(\"âœ… ç¿»è¯‘è¯å…¸åŠ è½½æˆåŠŸã€‚\")\n",
    "        return idx_to_label\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ğŸ›‘ é”™è¯¯: æ˜ å°„æ–‡ä»¶æœªæ‰¾åˆ°äº '{json_path}'\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"ğŸ›‘ é”™è¯¯: '{json_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONæ–‡ä»¶ã€‚\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 3. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "# ====================================================================\n",
    "def load_model(model_name, num_classes, model_path, device):\n",
    "    \"\"\"åŠ è½½æ¨¡å‹æ¶æ„å¹¶è½½å…¥è®­ç»ƒå¥½çš„æƒé‡\"\"\"\n",
    "    try:\n",
    "        # pretrained=False, å› ä¸ºæˆ‘ä»¬è¦åŠ è½½è‡ªå·±çš„æœ¬åœ°æƒé‡\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "        # ä½¿ç”¨ map_location=device ç¡®ä¿æ— è®ºæ¨¡å‹åœ¨GPUè¿˜æ˜¯CPUä¸Šè®­ç»ƒï¼Œéƒ½èƒ½åœ¨å½“å‰è®¾å¤‡æ­£ç¡®åŠ è½½\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼Œè¿™éå¸¸é‡è¦ï¼\n",
    "        print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚\")\n",
    "        return model\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ğŸ›‘ é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°äº '{model_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ›‘ åŠ è½½æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 4. å®šä¹‰å›¾åƒé¢„å¤„ç†æµç¨‹\n",
    "# ====================================================================\n",
    "# æ¨ç†æ—¶ä½¿ç”¨çš„å›¾åƒè½¬æ¢ï¼Œå¿…é¡»ä¸è®­ç»ƒæ—¶çš„éªŒè¯/æµ‹è¯•é›†è½¬æ¢å®Œå…¨ä¸€è‡´\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Define Image Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 5. æ ¸å¿ƒé¢„æµ‹å‡½æ•°\n",
    "# ====================================================================\n",
    "def predict_top3(model, image_path, transforms, idx_to_label_map, device):\n",
    "    \"\"\"å¯¹å•å¼ å›¾ç‰‡è¿›è¡ŒTop-3é¢„æµ‹ï¼Œåªè¾“å‡ºIDå’Œæ¦‚ç‡\"\"\"\n",
    "    try:\n",
    "        # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        # .unsqueeze(0) æ˜¯ä¸ºäº†å¢åŠ ä¸€ä¸ªbatchç»´åº¦ï¼Œå› ä¸ºæ¨¡å‹éœ€è¦ [B, C, H, W] å½¢çŠ¶çš„è¾“å…¥\n",
    "        image_tensor = transforms(image).unsqueeze(0).to(device)\n",
    "    except FileNotFoundError:\n",
    "        return f\"ğŸ›‘ é”™è¯¯: å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°äº '{image_path}'\"\n",
    "    except Exception as e:\n",
    "        return f\"ğŸ›‘ å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}\"\n",
    "\n",
    "    # å…³é—­æ¢¯åº¦è®¡ç®—ï¼Œèƒ½åŠ é€Ÿæ¨ç†å¹¶èŠ‚çœæ˜¾å­˜\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "\n",
    "    # åº”ç”¨Softmaxå‡½æ•°å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    \n",
    "    # è·å–æ¦‚ç‡æœ€é«˜çš„3ä¸ªå€¼å’Œå®ƒä»¬å¯¹åº”çš„ç´¢å¼•\n",
    "    top3_probs, top3_indices = torch.topk(probabilities, 3, dim=1)\n",
    "\n",
    "    # å°†Tensorä»GPUç§»åŠ¨åˆ°CPUï¼Œå¹¶è½¬æ¢ä¸ºNumpyæ•°ç»„ä»¥ä¾¿å¤„ç†\n",
    "    top3_probs = top3_probs.squeeze().cpu().numpy()\n",
    "    top3_indices = top3_indices.squeeze().cpu().numpy()\n",
    "    \n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        class_idx = top3_indices[i]\n",
    "        # **å…³é”®ç¿»è¯‘æ­¥éª¤**ï¼šå°†æ¨¡å‹çš„å†…éƒ¨ç´¢å¼•(class_idx)è½¬æ¢ä¸ºçœŸå®ID(class_id)\n",
    "        class_id = idx_to_label_map[class_idx]\n",
    "        prob = top3_probs[i]\n",
    "        \n",
    "        results.append({\n",
    "            \"predicted_id\": int(class_id), # ç¡®ä¿IDæ˜¯æ•´æ•°\n",
    "            \"probability\": f\"{prob:.2%}\"   # æ ¼å¼åŒ–ä¸ºç™¾åˆ†æ¯”å­—ç¬¦ä¸²\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Execute Inference and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- å¼€å§‹æ¤ç‰©ç—…å®³è¯†åˆ«æ¨ç† ---\n",
      "ä½¿ç”¨è®¾å¤‡: cuda\n",
      "\n",
      "[1/3] æ­£åœ¨åŠ è½½æ ‡ç­¾æ˜ å°„è¡¨...\n",
      "âœ… ç¿»è¯‘è¯å…¸åŠ è½½æˆåŠŸã€‚\n",
      "\n",
      "[2/3] æ­£åœ¨åŠ è½½æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹åŠ è½½æˆåŠŸã€‚\n",
      "\n",
      "[3/3] æ­£åœ¨æ‰§è¡Œé¢„æµ‹...\n",
      "\n",
      "==============================\n",
      "--- é¢„æµ‹ç»“æœ (Top 3) ---\n",
      "å›¾ç‰‡: test_images/011d0.jfif\n",
      "==============================\n",
      "ç—…å®³ID: 0     | æ¦‚ç‡: 89.83%\n",
      "ç—…å®³ID: 31    | æ¦‚ç‡: 0.72%\n",
      "ç—…å®³ID: 22    | æ¦‚ç‡: 0.68%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# 6. ä¸»æ‰§è¡Œå…¥å£\n",
    "# ====================================================================\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- å¼€å§‹æ¤ç‰©ç—…å®³è¯†åˆ«æ¨ç† ---\")\n",
    "    print(f\"ä½¿ç”¨è®¾å¤‡: {CFG.DEVICE}\")\n",
    "    \n",
    "    # æ­¥éª¤ 1: åŠ è½½ç¿»è¯‘è¯å…¸\n",
    "    print(\"\\n[1/3] æ­£åœ¨åŠ è½½æ ‡ç­¾æ˜ å°„è¡¨...\")\n",
    "    idx_to_label = load_class_map(CFG.CLASS_MAP_PATH)\n",
    "    \n",
    "    # æ­¥éª¤ 2: åŠ è½½æ¨¡å‹\n",
    "    if idx_to_label is not None:\n",
    "        print(\"\\n[2/3] æ­£åœ¨åŠ è½½æ¨¡å‹...\")\n",
    "        # æ¨¡å‹çš„ç±»åˆ«æ•°å¿…é¡»ä¸ç¿»è¯‘è¯å…¸çš„å¤§å°ä¸€è‡´\n",
    "        num_classes = len(idx_to_label)\n",
    "        model = load_model(CFG.MODEL_NAME, num_classes, CFG.MODEL_PATH, CFG.DEVICE)\n",
    "    else:\n",
    "        model = None\n",
    "\n",
    "    # æ­¥éª¤ 3: æ‰§è¡Œé¢„æµ‹\n",
    "    if model is not None:\n",
    "        print(\"\\n[3/3] æ­£åœ¨æ‰§è¡Œé¢„æµ‹...\")\n",
    "        # !! éœ€è¦ä½ æŒ‡å®šä¸€å¼ æœ¬åœ°å›¾ç‰‡çš„è·¯å¾„ !!\n",
    "        TEST_IMAGE_PATH = \"test_images/011d0.jfif\" # <--- åœ¨è¿™é‡Œä¿®æ”¹ä¸ºä½ æœ¬åœ°çš„æµ‹è¯•å›¾ç‰‡è·¯å¾„\n",
    "\n",
    "        if Path(TEST_IMAGE_PATH).exists():\n",
    "            top3_predictions = predict_top3(model, TEST_IMAGE_PATH, inference_transforms, idx_to_label, CFG.DEVICE)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"--- é¢„æµ‹ç»“æœ (Top 3) ---\")\n",
    "            print(f\"å›¾ç‰‡: {TEST_IMAGE_PATH}\")\n",
    "            print(\"=\"*30)\n",
    "            for pred in top3_predictions:\n",
    "                print(f\"ç—…å®³ID: {pred['predicted_id']:<5} | æ¦‚ç‡: {pred['probability']}\")\n",
    "        else:\n",
    "            print(f\"ğŸ›‘ é”™è¯¯: æµ‹è¯•å›¾ç‰‡ '{TEST_IMAGE_PATH}' ä¸å­˜åœ¨ã€‚è¯·ä¿®æ”¹è·¯å¾„åé‡è¯•ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
