{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c3056b",
   "metadata": {},
   "source": [
    "\n",
    "# Australian Threatened Plants (TSX): Data Wrangling and MySQL Ingestion\n",
    "\n",
    "Name: Zihan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcf1b1",
   "metadata": {},
   "source": [
    "### Step 1: Extract, Transform Species and Location Metadata\n",
    "\n",
    "This step's code performs the following operations:\n",
    "1.  Use `pandas` library to read original aggregated dataset `06_tsx-aggregated-data-dataset_for_aus_plants.csv`.\n",
    "2.  Select key columns related to species classification, conservation status, and geographic location based on specified column list.\n",
    "3.  Convert numeric values (1 and 0) in `NationalPriorityTaxa` column to more readable text ('Yes' and 'No').\n",
    "4.  Save extracted and processed subset data to new CSV file `Table16_TSX_SpeciesMonitoringTable.csv` in `02_wrangled_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b670229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取原始文件: 01_raw_data/06_tsx-aggregated-data-dataset_for_aus_plants.csv\n",
      "已将 'NationalPriorityTaxa' 列从 1/0 转换为 Yes/No。\n",
      "--------------------------------------------------\n",
      "成功提取并转换数据！\n",
      "新的文件已保存至: 02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv\n",
      "新文件包含 937 行 和 19 列。\n",
      "--------------------------------------------------\n",
      "转换后 'NationalPriorityTaxa' 列的预览:\n",
      "0    No\n",
      "1    No\n",
      "2    No\n",
      "3    No\n",
      "4    No\n",
      "Name: NationalPriorityTaxa, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Define file paths ---\n",
    "# Original data file path\n",
    "source_file_path = '01_raw_data/06_tsx-aggregated-data-dataset_for_aus_plants.csv'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "# --- 2. Define list of columns to extract ---\n",
    "# Note: 'ID' in original file is uppercase, maintain consistency here\n",
    "columns_to_extract = [\n",
    "    'ID',\n",
    "    'Binomial',\n",
    "    'CommonName',\n",
    "    'FamilyCommonName',\n",
    "    'Class',\n",
    "    'Order',\n",
    "    'Family',\n",
    "    'Genus',\n",
    "    'Species',\n",
    "    'Subspecies',\n",
    "    'FunctionalGroup',\n",
    "    'EPBCStatus',\n",
    "    'IUCNStatus',\n",
    "    'MaxStatus',\n",
    "    'NationalPriorityTaxa',\n",
    "    'State',\n",
    "    'Region',\n",
    "    'RegionCentroidLatitude',\n",
    "    'RegionCentroidLongitude'\n",
    "]\n",
    "\n",
    "# --- 3. Ensure output directory exists ---\n",
    "# Get directory containing output file\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 4. Execute data extraction, transformation and saving ---\n",
    "try:\n",
    "    # Read original CSV file\n",
    "    print(f\"Reading original file: {source_file_path}\")\n",
    "    df_raw = pd.read_csv(source_file_path)\n",
    "    \n",
    "    # Select specified columns from DataFrame\n",
    "    df_subset = df_raw[columns_to_extract].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # *** New step: Convert 'NationalPriorityTaxa' column ***\n",
    "    # Create mapping dictionary\n",
    "    mapping = {1: 'Yes', 0: 'No'}\n",
    "    # Apply mapping\n",
    "    df_subset['NationalPriorityTaxa'] = df_subset['NationalPriorityTaxa'].map(mapping)\n",
    "    print(\"Converted 'NationalPriorityTaxa' column from 1/0 to Yes/No.\")\n",
    "    \n",
    "    # Save extracted data to new CSV file without index column\n",
    "    df_subset.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Data successfully extracted and transformed!\")\n",
    "    print(f\"New file saved to: {output_file_path}\")\n",
    "    print(f\"New file contains {df_subset.shape[0]} rows and {df_subset.shape[1]} columns.\")\n",
    "    print(\"-\" * 50)\n",
    "    # Display first few rows of converted column for verification\n",
    "    print(\"Preview of converted 'NationalPriorityTaxa' column:\")\n",
    "    print(df_subset['NationalPriorityTaxa'].head())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Original file not found. Please confirm file path is correct: {source_file_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Original file missing one or more specified columns. Missing column: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unknown error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6b474",
   "metadata": {},
   "source": [
    "### Step 1 - Load Processed Data for Verification\n",
    "This step loads the cleaned and transformed CSV file from previous step and performs quick preview to ensure data is correct before uploading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已处理的CSV文件加载成功！\n",
      "\n",
      "==================================================\n",
      "\n",
      "数据信息概览：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 937 entries, 0 to 936\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       937 non-null    int64  \n",
      " 1   Binomial                 937 non-null    object \n",
      " 2   CommonName               850 non-null    object \n",
      " 3   FamilyCommonName         0 non-null      float64\n",
      " 4   Class                    0 non-null      float64\n",
      " 5   Order                    937 non-null    object \n",
      " 6   Family                   937 non-null    object \n",
      " 7   Genus                    937 non-null    object \n",
      " 8   Species                  937 non-null    object \n",
      " 9   Subspecies               76 non-null     object \n",
      " 10  FunctionalGroup          937 non-null    object \n",
      " 11  EPBCStatus               932 non-null    object \n",
      " 12  IUCNStatus               149 non-null    object \n",
      " 13  MaxStatus                937 non-null    object \n",
      " 14  NationalPriorityTaxa     937 non-null    object \n",
      " 15  State                    937 non-null    object \n",
      " 16  Region                   937 non-null    object \n",
      " 17  RegionCentroidLatitude   937 non-null    float64\n",
      " 18  RegionCentroidLongitude  937 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(14)\n",
      "memory usage: 139.2+ KB\n",
      "\n",
      "数据预览（前5行）：\n",
      "     ID                                 Binomial CommonName  FamilyCommonName  \\\n",
      "0  4714  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "1  4715  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "2  4716  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "3  4717  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "4  4718    Banksia_ionthocarpa_subsp_ionthocarpa        NaN               NaN   \n",
      "\n",
      "   Class      Order      Family    Genus      Species            Subspecies  \\\n",
      "0    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "1    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "2    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "3    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "4    NaN  Proteales  Proteaceae  Banksia  ionthocarpa    subsp. ionthocarpa   \n",
      "\n",
      "  FunctionalGroup  EPBCStatus  IUCNStatus   MaxStatus NationalPriorityTaxa  \\\n",
      "0           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "1           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "2           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "3           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "4           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "\n",
      "               State      Region  RegionCentroidLatitude  \\\n",
      "0  Western Australia   Katanning              -32.413329   \n",
      "1  Western Australia   Katanning              -32.413329   \n",
      "2  Western Australia   Katanning              -32.413329   \n",
      "3  Western Australia   Katanning              -32.413329   \n",
      "4  Western Australia  Fitzgerald              -34.230741   \n",
      "\n",
      "   RegionCentroidLongitude  \n",
      "0               117.179276  \n",
      "1               117.179276  \n",
      "2               117.179276  \n",
      "3               117.179276  \n",
      "4               119.150439  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define path to our processed data file\n",
    "wrangled_file_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "# Read data into DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(wrangled_file_path)\n",
    "    print(\"✅ Processed CSV file loaded successfully!\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"Data overview:\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\nData preview (first 5 rows):\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found. Please check path '{wrangled_file_path}' is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error occurred during processing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7f374",
   "metadata": {},
   "source": [
    "### Step 2 - Create Database Table Structure for `Table16_TSX_SpeciesMonitoringTable`\n",
    "This step connects to your MySQL database, drops any existing old table, then creates new, properly structured table based on specified columns and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [任务 1/4] 正在创建表 'Table16_TSX_SpeciesMonitoringTable'... ---\n",
      "✅ 成功连接到MySQL服务器\n",
      "正在删除旧表 'Table16_TSX_SpeciesMonitoringTable' (如果存在)...\n",
      "旧表已删除。\n",
      "✅ 表 'Table16_TSX_SpeciesMonitoringTable' 的结构创建成功。\n",
      "🔌 已关闭用于创建表结构的MySQL连接。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Database connection configuration (consistent with what you provided)\n",
    "db_config = {\n",
    "    'host': 'database-plantx.cqz06uycysiz.us-east-1.rds.amazonaws.com',\n",
    "    'user': 'zihan',\n",
    "    'password': '2002317Yzh12138.',\n",
    "    'database': 'FIT5120_PlantX_Database',\n",
    "    'allow_local_infile': True,\n",
    "    'use_pure': True,\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "# --- Task: Create table structure ---\n",
    "print(\"--- [Task 1/4] Creating table 'Table16_TSX_SpeciesMonitoringTable'... ---\")\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"✅ Successfully connected to MySQL server\")\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        print(f\"Dropping old table '{table_name}' (if exists)...\")\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        print(\"Old table dropped.\")\n",
    "\n",
    "        # SQL statement to create table based on your data types\n",
    "        create_table_16 = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            ID INT PRIMARY KEY,\n",
    "            Binomial TEXT,\n",
    "            CommonName TEXT,\n",
    "            FamilyCommonName TEXT,\n",
    "            `Class` TEXT,\n",
    "            `Order` TEXT,\n",
    "            Family TEXT,\n",
    "            Genus TEXT,\n",
    "            Species TEXT,\n",
    "            Subspecies TEXT,\n",
    "            FunctionalGroup TEXT,\n",
    "            EPBCStatus TEXT,\n",
    "            IUCNStatus TEXT,\n",
    "            MaxStatus TEXT,\n",
    "            NationalPriorityTaxa TEXT,\n",
    "            State TEXT,\n",
    "            Region TEXT,\n",
    "            RegionCentroidLatitude DOUBLE,\n",
    "            RegionCentroidLongitude DOUBLE,\n",
    "            -- Add spatial data column with temporary default value to support LOAD DATA\n",
    "            coords POINT NOT NULL DEFAULT (POINT(0,0)),\n",
    "            SPATIAL INDEX(coords)\n",
    "        ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n",
    "        \"\"\"\n",
    "        # Note: `Class` and `Order` are SQL reserved keywords, so enclose them in backticks ``\n",
    "        \n",
    "        cursor.execute(create_table_16)\n",
    "        connection.commit()\n",
    "        print(f\"✅ Table '{table_name}' structure created successfully.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"❌ Error creating table structure: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"🔌 MySQL connection for table creation closed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f9d69",
   "metadata": {},
   "source": [
    "### Step 3 - Import Data into `Table16_TSX_SpeciesMonitoringTable`\n",
    "Use `LOAD DATA LOCAL INFILE` to efficiently bulk import CSV data into newly created database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功连接到MySQL服务器，准备导入Table16数据。\n",
      "✅ Table16数据导入成功！影响行数: 937。\n",
      "🔌 已关闭用于导入Table16数据的MySQL连接。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Re-establish connection for data import\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"✅ Successfully connected to MySQL server, preparing to import Table16 data.\")\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        csv_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "        # Define query to load data\n",
    "        load_data_query_16 = f\"\"\"\n",
    "        LOAD DATA LOCAL INFILE '{csv_path}'\n",
    "        INTO TABLE {table_name}\n",
    "        CHARACTER SET utf8mb4\n",
    "        FIELDS TERMINATED BY ','\n",
    "        OPTIONALLY ENCLOSED BY '\"'\n",
    "        LINES TERMINATED BY '\\\\r\\\\n'\n",
    "        IGNORE 1 LINES\n",
    "        (\n",
    "            ID, Binomial, CommonName, FamilyCommonName, `Class`, `Order`, Family,\n",
    "            Genus, Species, Subspecies, FunctionalGroup, EPBCStatus, IUCNStatus,\n",
    "            MaxStatus, NationalPriorityTaxa, State, Region,\n",
    "            RegionCentroidLatitude, RegionCentroidLongitude\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(load_data_query_16)\n",
    "        connection.commit()\n",
    "        print(f\"✅ Table16 data imported successfully! Rows affected: {cursor.rowcount}.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"❌ Error importing Table16 data: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"🔌 MySQL connection for Table16 data import closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bba66",
   "metadata": {},
   "source": [
    "### Step 4 - Populate Spatial Data Column (coords)\n",
    "This step uses imported latitude/longitude data to populate `coords` spatial column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c1a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功连接到MySQL服务器，准备更新空间列。\n",
      "✅ 空间列 'coords' 填充成功！更新行数: 937。\n",
      "🔌 已关闭用于更新空间列的MySQL连接。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Re-establish connection to update spatial column\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"✅ Successfully connected to MySQL server, preparing to update spatial column.\")\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        \n",
    "        # SQL statement: Populate 'coords' column from lat/lon (POINT function uses longitude, latitude order)\n",
    "        update_spatial_column = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET coords = POINT(RegionCentroidLongitude, RegionCentroidLatitude)\n",
    "        WHERE RegionCentroidLongitude IS NOT NULL AND RegionCentroidLatitude IS NOT NULL;\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(update_spatial_column)\n",
    "        connection.commit()\n",
    "        print(f\"✅ Spatial column 'coords' populated successfully! Updated rows: {cursor.rowcount}.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"❌ Error updating spatial column: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"🔌 MySQL connection for spatial column update closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efc3f2",
   "metadata": {},
   "source": [
    "### Step 5 - Verify Imported Data\n",
    "Finally, we connect to database to query total row count and preview first few rows to ensure all content imported correctly, especially `coords` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 成功连接到MySQL服务器，准备验证Table16数据。\n",
      "📊 表 'Table16_TSX_SpeciesMonitoringTable' 当前包含 937 行。\n",
      "\n",
      "--- 'Table16_TSX_SpeciesMonitoringTable' 表前5行数据预览 ---\n",
      "ID     | Binomial                                      | Region               | coords\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4714   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4715   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4716   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4717   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4718   | Banksia_ionthocarpa_subsp_ionthocarpa         | Fitzgerald           | POINT(119.1504387 -34.23074081)\n",
      "\n",
      "🔌 已关闭用于验证Table16数据的MySQL连接。\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"\\n✅ Successfully connected to MySQL server, preparing to verify Table16 data.\")\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "\n",
    "        # Get total row count in table\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        print(f\"📊 Table '{table_name}' currently contains {row_count} rows.\")\n",
    "\n",
    "        # Get and print first 5 rows for preview\n",
    "        print(f\"\\n--- '{table_name}' table first 5 rows preview ---\")\n",
    "        # Use ST_AsText() to display POINT data in readable format\n",
    "        query = f\"\"\"\n",
    "        SELECT ID, Binomial, Region, \n",
    "               RegionCentroidLatitude, RegionCentroidLongitude, ST_AsText(coords) \n",
    "        FROM {table_name} \n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Print table header\n",
    "        print(f\"{'ID':<6} | {'Binomial':<45} | {'Region':<20} | {'coords'}\")\n",
    "        print(\"-\" * 100)\n",
    "        for row in rows:\n",
    "            # Format output (ID, Binomial, Region, ST_AsText(coords))\n",
    "            print(f\"{row[0]:<6} | {row[1]:<45} | {row[2]:<20} | {row[5]}\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"❌ Error verifying Table16 data: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"\\n🔌 MySQL connection for Table16 data verification closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df9406",
   "metadata": {},
   "source": [
    "### Step 6 - Spatial Query Example: Find Plant Monitoring Areas Near Melbourne CBD\n",
    "Following SQL query demonstrates how to use `coords` column and spatial index to efficiently find all plant monitoring areas within specified radius of given coordinate point (Melbourne CBD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013a017",
   "metadata": {},
   "source": [
    "#### Chinese Version\n",
    "```sql\n",
    "-- 设置目标坐标（墨尔本市中心：经度144.9631, 纬度-37.8136）和搜索半径（100公里）\n",
    "SET @center_point = POINT(144.9631, -37.8136);\n",
    "SET @radius_meters = 100 * 1000; -- 100公里转换为米\n",
    "\n",
    "SELECT\n",
    "    ID,\n",
    "    Binomial,\n",
    "    CommonName,\n",
    "    Region,\n",
    "    State,\n",
    "    -- 使用 ST_Distance_Sphere 计算精确的球面距离（单位：米）\n",
    "    -- 并将其转换为公里以便阅读\n",
    "    (ST_Distance_Sphere(coords, @center_point) / 1000) AS distance_in_km\n",
    "FROM\n",
    "    Table16_TSX_SpeciesMonitoringTable\n",
    "WHERE\n",
    "    -- 在 WHERE 子句中直接使用该函数进行高效筛选\n",
    "    -- MySQL会利用空间索引来优化这个查询，避免全表扫描\n",
    "    ST_Distance_Sphere(coords, @center_point) <= @radius_meters\n",
    "ORDER BY\n",
    "    distance_in_km ASC; -- 按距离从近到远排序\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b1764",
   "metadata": {},
   "source": [
    "#### English Version\n",
    "```sql\n",
    "-- Set the target coordinates (Melbourne CBD: Longitude 144.9631, Latitude -37.8136) and search radius (100 km)\n",
    "SET @center_point = POINT(144.9631, -37.8136);\n",
    "SET @radius_meters = 100 * 1000; -- Convert 100 km to meters\n",
    "\n",
    "SELECT\n",
    "    -- Select key identifiers for the monitoring site\n",
    "    ID,\n",
    "    Binomial,\n",
    "    CommonName,\n",
    "    Region,\n",
    "    State,\n",
    "\n",
    "    -- Calculate the great-circle distance on a sphere, returning the result in meters.\n",
    "    -- Then, convert it to kilometers for better readability.\n",
    "    (ST_Distance_Sphere(coords, @center_point) / 1000) AS distance_in_km\n",
    "FROM\n",
    "    -- Specify the table containing the threatened species monitoring data.\n",
    "    Table16_TSX_SpeciesMonitoringTable\n",
    "WHERE\n",
    "    -- Filter results to include only records within the specified radius of the central point.\n",
    "    -- This operation is highly efficient as it leverages the SPATIAL INDEX on the 'coords' column,\n",
    "    -- preventing a full table scan.\n",
    "    ST_Distance_Sphere(coords, @center_point) <= @radius_meters\n",
    "ORDER BY\n",
    "    -- Sort the results by distance, from nearest to farthest.\n",
    "    distance_in_km ASC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
