{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c3056b",
   "metadata": {},
   "source": [
    "\n",
    "# Australian Threatened Plants (TSX): Data Wrangling and MySQL Ingestion\n",
    "\n",
    "Name: Zihan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcf1b1",
   "metadata": {},
   "source": [
    "### Step 1: Extract, Transform Species and Location Metadata\n",
    "\n",
    "This step's code performs the following operations:\n",
    "1.  Use `pandas` library to read original aggregated dataset `06_tsx-aggregated-data-dataset_for_aus_plants.csv`.\n",
    "2.  Select key columns related to species classification, conservation status, and geographic location based on specified column list.\n",
    "3.  Convert numeric values (1 and 0) in `NationalPriorityTaxa` column to more readable text ('Yes' and 'No').\n",
    "4.  Save extracted and processed subset data to new CSV file `Table16_TSX_SpeciesMonitoringTable.csv` in `02_wrangled_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b670229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å–åŸå§‹æ–‡ä»¶: 01_raw_data/06_tsx-aggregated-data-dataset_for_aus_plants.csv\n",
      "å·²å°† 'NationalPriorityTaxa' åˆ—ä» 1/0 è½¬æ¢ä¸º Yes/Noã€‚\n",
      "--------------------------------------------------\n",
      "æˆåŠŸæå–å¹¶è½¬æ¢æ•°æ®ï¼\n",
      "æ–°çš„æ–‡ä»¶å·²ä¿å­˜è‡³: 02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv\n",
      "æ–°æ–‡ä»¶åŒ…å« 937 è¡Œ å’Œ 19 åˆ—ã€‚\n",
      "--------------------------------------------------\n",
      "è½¬æ¢å 'NationalPriorityTaxa' åˆ—çš„é¢„è§ˆ:\n",
      "0    No\n",
      "1    No\n",
      "2    No\n",
      "3    No\n",
      "4    No\n",
      "Name: NationalPriorityTaxa, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Define file paths ---\n",
    "# Original data file path\n",
    "source_file_path = '01_raw_data/06_tsx-aggregated-data-dataset_for_aus_plants.csv'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "# --- 2. Define list of columns to extract ---\n",
    "# Note: 'ID' in original file is uppercase, maintain consistency here\n",
    "columns_to_extract = [\n",
    "    'ID',\n",
    "    'Binomial',\n",
    "    'CommonName',\n",
    "    'FamilyCommonName',\n",
    "    'Class',\n",
    "    'Order',\n",
    "    'Family',\n",
    "    'Genus',\n",
    "    'Species',\n",
    "    'Subspecies',\n",
    "    'FunctionalGroup',\n",
    "    'EPBCStatus',\n",
    "    'IUCNStatus',\n",
    "    'MaxStatus',\n",
    "    'NationalPriorityTaxa',\n",
    "    'State',\n",
    "    'Region',\n",
    "    'RegionCentroidLatitude',\n",
    "    'RegionCentroidLongitude'\n",
    "]\n",
    "\n",
    "# --- 3. Ensure output directory exists ---\n",
    "# Get directory containing output file\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 4. Execute data extraction, transformation and saving ---\n",
    "try:\n",
    "    # Read original CSV file\n",
    "    print(f\"Reading original file: {source_file_path}\")\n",
    "    df_raw = pd.read_csv(source_file_path)\n",
    "    \n",
    "    # Select specified columns from DataFrame\n",
    "    df_subset = df_raw[columns_to_extract].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # *** New step: Convert 'NationalPriorityTaxa' column ***\n",
    "    # Create mapping dictionary\n",
    "    mapping = {1: 'Yes', 0: 'No'}\n",
    "    # Apply mapping\n",
    "    df_subset['NationalPriorityTaxa'] = df_subset['NationalPriorityTaxa'].map(mapping)\n",
    "    print(\"Converted 'NationalPriorityTaxa' column from 1/0 to Yes/No.\")\n",
    "    \n",
    "    # Save extracted data to new CSV file without index column\n",
    "    df_subset.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Data successfully extracted and transformed!\")\n",
    "    print(f\"New file saved to: {output_file_path}\")\n",
    "    print(f\"New file contains {df_subset.shape[0]} rows and {df_subset.shape[1]} columns.\")\n",
    "    print(\"-\" * 50)\n",
    "    # Display first few rows of converted column for verification\n",
    "    print(\"Preview of converted 'NationalPriorityTaxa' column:\")\n",
    "    print(df_subset['NationalPriorityTaxa'].head())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Original file not found. Please confirm file path is correct: {source_file_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Original file missing one or more specified columns. Missing column: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unknown error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6b474",
   "metadata": {},
   "source": [
    "### Step 1 - Load Processed Data for Verification\n",
    "This step loads the cleaned and transformed CSV file from previous step and performs quick preview to ensure data is correct before uploading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²å¤„ç†çš„CSVæ–‡ä»¶åŠ è½½æˆåŠŸï¼\n",
      "\n",
      "==================================================\n",
      "\n",
      "æ•°æ®ä¿¡æ¯æ¦‚è§ˆï¼š\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 937 entries, 0 to 936\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       937 non-null    int64  \n",
      " 1   Binomial                 937 non-null    object \n",
      " 2   CommonName               850 non-null    object \n",
      " 3   FamilyCommonName         0 non-null      float64\n",
      " 4   Class                    0 non-null      float64\n",
      " 5   Order                    937 non-null    object \n",
      " 6   Family                   937 non-null    object \n",
      " 7   Genus                    937 non-null    object \n",
      " 8   Species                  937 non-null    object \n",
      " 9   Subspecies               76 non-null     object \n",
      " 10  FunctionalGroup          937 non-null    object \n",
      " 11  EPBCStatus               932 non-null    object \n",
      " 12  IUCNStatus               149 non-null    object \n",
      " 13  MaxStatus                937 non-null    object \n",
      " 14  NationalPriorityTaxa     937 non-null    object \n",
      " 15  State                    937 non-null    object \n",
      " 16  Region                   937 non-null    object \n",
      " 17  RegionCentroidLatitude   937 non-null    float64\n",
      " 18  RegionCentroidLongitude  937 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(14)\n",
      "memory usage: 139.2+ KB\n",
      "\n",
      "æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰ï¼š\n",
      "     ID                                 Binomial CommonName  FamilyCommonName  \\\n",
      "0  4714  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "1  4715  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "2  4716  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "3  4717  Banksia_ionthocarpa_subsp_chrysophoenix        NaN               NaN   \n",
      "4  4718    Banksia_ionthocarpa_subsp_ionthocarpa        NaN               NaN   \n",
      "\n",
      "   Class      Order      Family    Genus      Species            Subspecies  \\\n",
      "0    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "1    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "2    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "3    NaN  Proteales  Proteaceae  Banksia  ionthocarpa  subsp. chrysophoenix   \n",
      "4    NaN  Proteales  Proteaceae  Banksia  ionthocarpa    subsp. ionthocarpa   \n",
      "\n",
      "  FunctionalGroup  EPBCStatus  IUCNStatus   MaxStatus NationalPriorityTaxa  \\\n",
      "0           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "1           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "2           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "3           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "4           Shrub  Endangered  Endangered  Endangered                   No   \n",
      "\n",
      "               State      Region  RegionCentroidLatitude  \\\n",
      "0  Western Australia   Katanning              -32.413329   \n",
      "1  Western Australia   Katanning              -32.413329   \n",
      "2  Western Australia   Katanning              -32.413329   \n",
      "3  Western Australia   Katanning              -32.413329   \n",
      "4  Western Australia  Fitzgerald              -34.230741   \n",
      "\n",
      "   RegionCentroidLongitude  \n",
      "0               117.179276  \n",
      "1               117.179276  \n",
      "2               117.179276  \n",
      "3               117.179276  \n",
      "4               119.150439  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define path to our processed data file\n",
    "wrangled_file_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "# Read data into DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(wrangled_file_path)\n",
    "    print(\"âœ… Processed CSV file loaded successfully!\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"Data overview:\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\nData preview (first 5 rows):\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: File not found. Please check path '{wrangled_file_path}' is correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error occurred during processing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7f374",
   "metadata": {},
   "source": [
    "### Step 2 - Create Database Table Structure for `Table16_TSX_SpeciesMonitoringTable`\n",
    "This step connects to your MySQL database, drops any existing old table, then creates new, properly structured table based on specified columns and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [ä»»åŠ¡ 1/4] æ­£åœ¨åˆ›å»ºè¡¨ 'Table16_TSX_SpeciesMonitoringTable'... ---\n",
      "âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨\n",
      "æ­£åœ¨åˆ é™¤æ—§è¡¨ 'Table16_TSX_SpeciesMonitoringTable' (å¦‚æœå­˜åœ¨)...\n",
      "æ—§è¡¨å·²åˆ é™¤ã€‚\n",
      "âœ… è¡¨ 'Table16_TSX_SpeciesMonitoringTable' çš„ç»“æ„åˆ›å»ºæˆåŠŸã€‚\n",
      "ğŸ”Œ å·²å…³é—­ç”¨äºåˆ›å»ºè¡¨ç»“æ„çš„MySQLè¿æ¥ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Database connection configuration (consistent with what you provided)\n",
    "db_config = {\n",
    "    'host': 'database-plantx.cqz06uycysiz.us-east-1.rds.amazonaws.com',\n",
    "    'user': 'zihan',\n",
    "    'password': '2002317Yzh12138.',\n",
    "    'database': 'FIT5120_PlantX_Database',\n",
    "    'allow_local_infile': True,\n",
    "    'use_pure': True,\n",
    "    'charset': 'utf8mb4'\n",
    "}\n",
    "\n",
    "# --- Task: Create table structure ---\n",
    "print(\"--- [Task 1/4] Creating table 'Table16_TSX_SpeciesMonitoringTable'... ---\")\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"âœ… Successfully connected to MySQL server\")\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        print(f\"Dropping old table '{table_name}' (if exists)...\")\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        print(\"Old table dropped.\")\n",
    "\n",
    "        # SQL statement to create table based on your data types\n",
    "        create_table_16 = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            ID INT PRIMARY KEY,\n",
    "            Binomial TEXT,\n",
    "            CommonName TEXT,\n",
    "            FamilyCommonName TEXT,\n",
    "            `Class` TEXT,\n",
    "            `Order` TEXT,\n",
    "            Family TEXT,\n",
    "            Genus TEXT,\n",
    "            Species TEXT,\n",
    "            Subspecies TEXT,\n",
    "            FunctionalGroup TEXT,\n",
    "            EPBCStatus TEXT,\n",
    "            IUCNStatus TEXT,\n",
    "            MaxStatus TEXT,\n",
    "            NationalPriorityTaxa TEXT,\n",
    "            State TEXT,\n",
    "            Region TEXT,\n",
    "            RegionCentroidLatitude DOUBLE,\n",
    "            RegionCentroidLongitude DOUBLE,\n",
    "            -- Add spatial data column with temporary default value to support LOAD DATA\n",
    "            coords POINT NOT NULL DEFAULT (POINT(0,0)),\n",
    "            SPATIAL INDEX(coords)\n",
    "        ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n",
    "        \"\"\"\n",
    "        # Note: `Class` and `Order` are SQL reserved keywords, so enclose them in backticks ``\n",
    "        \n",
    "        cursor.execute(create_table_16)\n",
    "        connection.commit()\n",
    "        print(f\"âœ… Table '{table_name}' structure created successfully.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"âŒ Error creating table structure: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"ğŸ”Œ MySQL connection for table creation closed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f9d69",
   "metadata": {},
   "source": [
    "### Step 3 - Import Data into `Table16_TSX_SpeciesMonitoringTable`\n",
    "Use `LOAD DATA LOCAL INFILE` to efficiently bulk import CSV data into newly created database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨ï¼Œå‡†å¤‡å¯¼å…¥Table16æ•°æ®ã€‚\n",
      "âœ… Table16æ•°æ®å¯¼å…¥æˆåŠŸï¼å½±å“è¡Œæ•°: 937ã€‚\n",
      "ğŸ”Œ å·²å…³é—­ç”¨äºå¯¼å…¥Table16æ•°æ®çš„MySQLè¿æ¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Re-establish connection for data import\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"âœ… Successfully connected to MySQL server, preparing to import Table16 data.\")\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        csv_path = '02_wrangled_data/Table16_TSX_SpeciesMonitoringTable.csv'\n",
    "\n",
    "        # Define query to load data\n",
    "        load_data_query_16 = f\"\"\"\n",
    "        LOAD DATA LOCAL INFILE '{csv_path}'\n",
    "        INTO TABLE {table_name}\n",
    "        CHARACTER SET utf8mb4\n",
    "        FIELDS TERMINATED BY ','\n",
    "        OPTIONALLY ENCLOSED BY '\"'\n",
    "        LINES TERMINATED BY '\\\\r\\\\n'\n",
    "        IGNORE 1 LINES\n",
    "        (\n",
    "            ID, Binomial, CommonName, FamilyCommonName, `Class`, `Order`, Family,\n",
    "            Genus, Species, Subspecies, FunctionalGroup, EPBCStatus, IUCNStatus,\n",
    "            MaxStatus, NationalPriorityTaxa, State, Region,\n",
    "            RegionCentroidLatitude, RegionCentroidLongitude\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(load_data_query_16)\n",
    "        connection.commit()\n",
    "        print(f\"âœ… Table16 data imported successfully! Rows affected: {cursor.rowcount}.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"âŒ Error importing Table16 data: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"ğŸ”Œ MySQL connection for Table16 data import closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bba66",
   "metadata": {},
   "source": [
    "### Step 4 - Populate Spatial Data Column (coords)\n",
    "This step uses imported latitude/longitude data to populate `coords` spatial column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c1a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨ï¼Œå‡†å¤‡æ›´æ–°ç©ºé—´åˆ—ã€‚\n",
      "âœ… ç©ºé—´åˆ— 'coords' å¡«å……æˆåŠŸï¼æ›´æ–°è¡Œæ•°: 937ã€‚\n",
      "ğŸ”Œ å·²å…³é—­ç”¨äºæ›´æ–°ç©ºé—´åˆ—çš„MySQLè¿æ¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Re-establish connection to update spatial column\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"âœ… Successfully connected to MySQL server, preparing to update spatial column.\")\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "        \n",
    "        # SQL statement: Populate 'coords' column from lat/lon (POINT function uses longitude, latitude order)\n",
    "        update_spatial_column = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET coords = POINT(RegionCentroidLongitude, RegionCentroidLatitude)\n",
    "        WHERE RegionCentroidLongitude IS NOT NULL AND RegionCentroidLatitude IS NOT NULL;\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(update_spatial_column)\n",
    "        connection.commit()\n",
    "        print(f\"âœ… Spatial column 'coords' populated successfully! Updated rows: {cursor.rowcount}.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"âŒ Error updating spatial column: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"ğŸ”Œ MySQL connection for spatial column update closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efc3f2",
   "metadata": {},
   "source": [
    "### Step 5 - Verify Imported Data\n",
    "Finally, we connect to database to query total row count and preview first few rows to ensure all content imported correctly, especially `coords` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨ï¼Œå‡†å¤‡éªŒè¯Table16æ•°æ®ã€‚\n",
      "ğŸ“Š è¡¨ 'Table16_TSX_SpeciesMonitoringTable' å½“å‰åŒ…å« 937 è¡Œã€‚\n",
      "\n",
      "--- 'Table16_TSX_SpeciesMonitoringTable' è¡¨å‰5è¡Œæ•°æ®é¢„è§ˆ ---\n",
      "ID     | Binomial                                      | Region               | coords\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4714   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4715   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4716   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4717   | Banksia_ionthocarpa_subsp_chrysophoenix       | Katanning            | POINT(117.1792762 -32.41332852)\n",
      "4718   | Banksia_ionthocarpa_subsp_ionthocarpa         | Fitzgerald           | POINT(119.1504387 -34.23074081)\n",
      "\n",
      "ğŸ”Œ å·²å…³é—­ç”¨äºéªŒè¯Table16æ•°æ®çš„MySQLè¿æ¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        print(\"\\nâœ… Successfully connected to MySQL server, preparing to verify Table16 data.\")\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        table_name = \"Table16_TSX_SpeciesMonitoringTable\"\n",
    "\n",
    "        # Get total row count in table\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        print(f\"ğŸ“Š Table '{table_name}' currently contains {row_count} rows.\")\n",
    "\n",
    "        # Get and print first 5 rows for preview\n",
    "        print(f\"\\n--- '{table_name}' table first 5 rows preview ---\")\n",
    "        # Use ST_AsText() to display POINT data in readable format\n",
    "        query = f\"\"\"\n",
    "        SELECT ID, Binomial, Region, \n",
    "               RegionCentroidLatitude, RegionCentroidLongitude, ST_AsText(coords) \n",
    "        FROM {table_name} \n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Print table header\n",
    "        print(f\"{'ID':<6} | {'Binomial':<45} | {'Region':<20} | {'coords'}\")\n",
    "        print(\"-\" * 100)\n",
    "        for row in rows:\n",
    "            # Format output (ID, Binomial, Region, ST_AsText(coords))\n",
    "            print(f\"{row[0]:<6} | {row[1]:<45} | {row[2]:<20} | {row[5]}\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"âŒ Error verifying Table16 data: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"\\nğŸ”Œ MySQL connection for Table16 data verification closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df9406",
   "metadata": {},
   "source": [
    "### Step 6 - Spatial Query Example: Find Plant Monitoring Areas Near Melbourne CBD\n",
    "Following SQL query demonstrates how to use `coords` column and spatial index to efficiently find all plant monitoring areas within specified radius of given coordinate point (Melbourne CBD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013a017",
   "metadata": {},
   "source": [
    "#### Chinese Version\n",
    "```sql\n",
    "-- è®¾ç½®ç›®æ ‡åæ ‡ï¼ˆå¢¨å°”æœ¬å¸‚ä¸­å¿ƒï¼šç»åº¦144.9631, çº¬åº¦-37.8136ï¼‰å’Œæœç´¢åŠå¾„ï¼ˆ100å…¬é‡Œï¼‰\n",
    "SET @center_point = POINT(144.9631, -37.8136);\n",
    "SET @radius_meters = 100 * 1000; -- 100å…¬é‡Œè½¬æ¢ä¸ºç±³\n",
    "\n",
    "SELECT\n",
    "    ID,\n",
    "    Binomial,\n",
    "    CommonName,\n",
    "    Region,\n",
    "    State,\n",
    "    -- ä½¿ç”¨ ST_Distance_Sphere è®¡ç®—ç²¾ç¡®çš„çƒé¢è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰\n",
    "    -- å¹¶å°†å…¶è½¬æ¢ä¸ºå…¬é‡Œä»¥ä¾¿é˜…è¯»\n",
    "    (ST_Distance_Sphere(coords, @center_point) / 1000) AS distance_in_km\n",
    "FROM\n",
    "    Table16_TSX_SpeciesMonitoringTable\n",
    "WHERE\n",
    "    -- åœ¨ WHERE å­å¥ä¸­ç›´æ¥ä½¿ç”¨è¯¥å‡½æ•°è¿›è¡Œé«˜æ•ˆç­›é€‰\n",
    "    -- MySQLä¼šåˆ©ç”¨ç©ºé—´ç´¢å¼•æ¥ä¼˜åŒ–è¿™ä¸ªæŸ¥è¯¢ï¼Œé¿å…å…¨è¡¨æ‰«æ\n",
    "    ST_Distance_Sphere(coords, @center_point) <= @radius_meters\n",
    "ORDER BY\n",
    "    distance_in_km ASC; -- æŒ‰è·ç¦»ä»è¿‘åˆ°è¿œæ’åº\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b1764",
   "metadata": {},
   "source": [
    "#### English Version\n",
    "```sql\n",
    "-- Set the target coordinates (Melbourne CBD: Longitude 144.9631, Latitude -37.8136) and search radius (100 km)\n",
    "SET @center_point = POINT(144.9631, -37.8136);\n",
    "SET @radius_meters = 100 * 1000; -- Convert 100 km to meters\n",
    "\n",
    "SELECT\n",
    "    -- Select key identifiers for the monitoring site\n",
    "    ID,\n",
    "    Binomial,\n",
    "    CommonName,\n",
    "    Region,\n",
    "    State,\n",
    "\n",
    "    -- Calculate the great-circle distance on a sphere, returning the result in meters.\n",
    "    -- Then, convert it to kilometers for better readability.\n",
    "    (ST_Distance_Sphere(coords, @center_point) / 1000) AS distance_in_km\n",
    "FROM\n",
    "    -- Specify the table containing the threatened species monitoring data.\n",
    "    Table16_TSX_SpeciesMonitoringTable\n",
    "WHERE\n",
    "    -- Filter results to include only records within the specified radius of the central point.\n",
    "    -- This operation is highly efficient as it leverages the SPATIAL INDEX on the 'coords' column,\n",
    "    -- preventing a full table scan.\n",
    "    ST_Distance_Sphere(coords, @center_point) <= @radius_meters\n",
    "ORDER BY\n",
    "    -- Sort the results by distance, from nearest to farthest.\n",
    "    distance_in_km ASC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
