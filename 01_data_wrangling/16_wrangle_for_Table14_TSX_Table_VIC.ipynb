{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546ca2e1",
   "metadata": {},
   "source": [
    "# Data Preparation: Enriching Threatened Species Index with Historical Weather Data for Time Series Analysis\n",
    "\n",
    "Name: Zihan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea7ec0",
   "metadata": {},
   "source": [
    "### Workflow Summary\n",
    "\n",
    "This Jupyter Notebook documents the complete process from raw data loading to final dataset generation, divided into four core steps:\n",
    "\n",
    "1.  **Main Data Processing (TSX Index Data Wrangling)**\n",
    "    * Load and merge Threatened Species Index (TSX Index) data from 6 different CSV files covering Australian states and national data.\n",
    "    * Standardize data, unify column names and formats, generate main dataset `combined_df` containing records from 2000 to 2021.\n",
    "\n",
    "2.  **External Data Strategy (External Data Strategy)**\n",
    "    * Determine strategy to enrich time series model predictive power by introducing historical weather data as exogenous variables.\n",
    "    * Select Open-Meteo historical weather API as data source, identify three key weather indicators: annual average temperature, annual total precipitation, annual total shortwave radiation.\n",
    "\n",
    "3.  **Weather Data Acquisition & Processing (Weather Data Acquisition & Processing)**\n",
    "    * Use official `openmeteo-requests` Python client with caching and auto-retry for stable, efficient data retrieval.\n",
    "    * Use state capital coordinates to call API, obtain daily weather data from 2000 to 2024.\n",
    "    * Aggregate daily data to annual level (temperature average, precipitation/radiation sum), calculate national (National) average indicators.\n",
    "    * Clean aggregated data, generate complete `weather_df` weather dataset.\n",
    "\n",
    "4.  **Final Data Merge & Storage (Final Merge & Storage)**\n",
    "    * Use **Right Merge** to combine main data (`combined_df`) with weather data (`weather_df`), generate final dataset `final_df` with complete 2000-2024 records.\n",
    "    * Save `final_df` as CSV file (`Table14_TSX_Table_VIC_version3.csv`) as direct input for next phase **SARIMAX model predictive analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba7373",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Set Paths\n",
    "\n",
    "In this cell, we import `pandas` and `os` libraries, then define directory path containing data files and filename list. This prepares for all subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8edeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库已导入，路径已设置。\n"
     ]
    }
   ],
   "source": [
    "# Cell 1\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory containing data files\n",
    "# Use forward slash '/' which works well on Windows, Mac, and Linux\n",
    "data_directory = '01_raw_data/06_tsx_table_vic'\n",
    "\n",
    "# Define list of target files to process (already renamed)\n",
    "target_files = [\n",
    "    \"National.csv\",\n",
    "    \"Australian_Capital_Territory.csv\",\n",
    "    \"New_South_Wales.csv\",\n",
    "    \"South_Australia.csv\",\n",
    "    \"Victoria.csv\",\n",
    "    \"Western_Australia.csv\"\n",
    "]\n",
    "\n",
    "print(\"Libraries imported, paths set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3964e5a",
   "metadata": {},
   "source": [
    "### Step 2: Loop Through, Process, and Merge Data\n",
    "\n",
    "This is the core processing step. Code iterates through each filename in `target_files` list:\n",
    "1.  Read corresponding CSV file.\n",
    "2.  Add `state` column based on filename.\n",
    "3.  Rename `value`, `low`, `high` columns.\n",
    "4.  Reorder columns according to final required sequence.\n",
    "5.  Store processed data (DataFrame) in temporary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b180c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始从目录 '01_raw_data/06_tsx_table_vic' 中处理文件...\n",
      "已处理: National.csv\n",
      "已处理: Australian_Capital_Territory.csv\n",
      "已处理: New_South_Wales.csv\n",
      "已处理: South_Australia.csv\n",
      "已处理: Victoria.csv\n",
      "已处理: Western_Australia.csv\n",
      "\n",
      "所有文件处理完毕。\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "# Initialize empty list to store each processed DataFrame\n",
    "all_dataframes = []\n",
    "\n",
    "print(f\"Starting to process files from directory '{data_directory}'...\")\n",
    "\n",
    "# Iterate through filename list\n",
    "for filename in target_files:\n",
    "    filepath = os.path.join(data_directory, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: File not found, skipping -> {filepath}\")\n",
    "        continue\n",
    "\n",
    "    # 1. Read CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # 2. Extract state/territory name from filename and add as new column\n",
    "    state = filename.replace('.csv', '').replace('_', ' ')\n",
    "    df['state'] = state\n",
    "    \n",
    "    # 3. Rename columns to match final structure\n",
    "    df.rename(columns={\n",
    "        'value': 'index_value',\n",
    "        'low': 'index_conf_low',\n",
    "        'high': 'index_conf_high'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # 4. Reorder columns according to specified sequence\n",
    "    df = df[['year', 'state', 'index_value', 'index_conf_low', 'index_conf_high']]\n",
    "    \n",
    "    # 5. Add processed DataFrame to list\n",
    "    all_dataframes.append(df)\n",
    "    \n",
    "    print(f\"Processed: {filename}\")\n",
    "\n",
    "print(\"\\nAll files processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef036a26",
   "metadata": {},
   "source": [
    "### Step 3: Final Merge and Data Type Conversion\n",
    "\n",
    "Previous step created list with 6 independent datasets. Now we merge them into single complete dataset and strictly convert each column's data type as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功合并并转换好数据类型。\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# Merge all DataFrames in list into one\n",
    "combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Ensure final data types are correct\n",
    "combined_df['year'] = combined_df['year'].astype(int)\n",
    "combined_df['state'] = combined_df['state'].astype(str)\n",
    "combined_df['index_value'] = combined_df['index_value'].astype(float)\n",
    "combined_df['index_conf_low'] = combined_df['index_conf_low'].astype(float)\n",
    "combined_df['index_conf_high'] = combined_df['index_conf_high'].astype(float)\n",
    "\n",
    "print(\"Data successfully merged and data types converted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710fb0b",
   "metadata": {},
   "source": [
    "### Step 4: Check Final Results\n",
    "\n",
    "Finally, we verify data is ready as expected using two commands:\n",
    "1.  `combined_df.head()`: Display first 5 rows of final dataset to visually check content and format.\n",
    "2.  `combined_df.info()`: Display dataset summary including total rows, column names, non-null counts, and data types to confirm structure is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9ed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 最终合并数据 (前5行) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>index_value</th>\n",
       "      <th>index_conf_low</th>\n",
       "      <th>index_conf_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>National</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>National</td>\n",
       "      <td>0.894786</td>\n",
       "      <td>0.779023</td>\n",
       "      <td>1.014265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>National</td>\n",
       "      <td>0.833242</td>\n",
       "      <td>0.717140</td>\n",
       "      <td>0.965727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>National</td>\n",
       "      <td>0.852811</td>\n",
       "      <td>0.712254</td>\n",
       "      <td>1.026288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>National</td>\n",
       "      <td>0.799586</td>\n",
       "      <td>0.658812</td>\n",
       "      <td>0.968141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     state  index_value  index_conf_low  index_conf_high\n",
       "0  2000  National     1.000000        1.000000         1.000000\n",
       "1  2001  National     0.894786        0.779023         1.014265\n",
       "2  2002  National     0.833242        0.717140         0.965727\n",
       "3  2003  National     0.852811        0.712254         1.026288\n",
       "4  2004  National     0.799586        0.658812         0.968141"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4\n",
    "# Display first 5 rows of final DataFrame to check data correctness\n",
    "print(\"--- Final Merged Data (First 5 Rows) ---\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4aa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 最终数据结构和类型 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132 entries, 0 to 131\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   year             132 non-null    int32  \n",
      " 1   state            132 non-null    object \n",
      " 2   index_value      132 non-null    float64\n",
      " 3   index_conf_low   132 non-null    float64\n",
      " 4   index_conf_high  132 non-null    float64\n",
      "dtypes: float64(3), int32(1), object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "# Display DataFrame structure information (column names, non-null counts, data types)\n",
    "print(\"\\n--- Final Data Structure and Types ---\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9192d30",
   "metadata": {},
   "source": [
    "### Step 5: Install, Setup, and Prepare Weather Data Parameters\n",
    "\n",
    "In this step, we adopt more professional, reliable data acquisition method: use official `openmeteo-requests` Python client. This cell completes all data acquisition preparations.\n",
    "\n",
    "**1. Reasons for Using Official Client:**\n",
    "-   **Smart Caching**: Automatically saves API responses locally for fast subsequent runs without consuming API resources.\n",
    "-   **Automatic Retries**: Automatically retries failed requests due to network fluctuations, greatly improving code stability.\n",
    "\n",
    "**2. Preparation Process in This Cell:**\n",
    "-   **Install Libraries**: Ensure `openmeteo-requests` and dependencies are installed.\n",
    "-   **Define Parameters**:\n",
    "    -   **Capital Coordinates**: Create dictionary with state capitals and their coordinates.\n",
    "    -   **API Parameters**: Define required weather variables and time range (2000-01-01 to 2024-12-31).\n",
    "-   **Setup Client**: Initialize API client with caching and retry functionality for next step's data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb546c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 官方API客户端已成功设置！\n"
     ]
    }
   ],
   "source": [
    "# 1. Install required libraries (if not already installed)\n",
    "# If running in Jupyter, use ! prefix to execute pip command\n",
    "# !pip install openmeteo-requests requests-cache retry-requests numpy pandas\n",
    "\n",
    "import openmeteo_requests\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "# 2. Setup Open-Meteo API client with caching and retry functionality\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "# 3. Redefine our parameters\n",
    "# Define capital city coordinates for each state/territory\n",
    "capital_coords = {\n",
    "    \"Victoria\": {\"lat\": -37.81, \"lon\": 144.96},\n",
    "    \"New South Wales\": {\"lat\": -33.87, \"lon\": 151.21},\n",
    "    \"South Australia\": {\"lat\": -34.93, \"lon\": 138.60},\n",
    "    \"Western Australia\": {\"lat\": -31.95, \"lon\": 115.86},\n",
    "    \"Australian Capital Territory\": {\"lat\": -35.28, \"lon\": 149.13},\n",
    "}\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2024-12-31\"\n",
    "base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# API client requires variables as list\n",
    "daily_vars_list = [\"precipitation_sum\", \"temperature_2m_mean\", \"shortwave_radiation_sum\"]\n",
    "\n",
    "print(\"✅ Official API client successfully set up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d44f56",
   "metadata": {},
   "source": [
    "### Step 6: Use Official Client to Acquire and Aggregate Weather Data\n",
    "\n",
    "Now we use the `openmeteo` client from previous step to acquire 2000-2024 weather data for each state.\n",
    "\n",
    "This code block performs these core operations:\n",
    "1.  Iterate through each state's capital coordinates.\n",
    "2.  Use official client to request 25 years of daily data for each state.\n",
    "3.  Efficiently parse returned data into Pandas DataFrame.\n",
    "4.  **Resample** daily data to annual level and **aggregate**:\n",
    "    -   Temperature: annual **average**.\n",
    "    -   Precipitation: annual **sum**.\n",
    "    -   Radiation: annual **sum**.\n",
    "5.  Store processed annual data in list for next merge step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caecbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 开始使用官方客户端获取并处理各州天气数据...\n",
      "\n",
      "--- 正在处理 [Victoria] ---\n",
      "✅ 已成功获取并处理完 [Victoria] 的数据。\n",
      "\n",
      "--- 正在处理 [New South Wales] ---\n",
      "✅ 已成功获取并处理完 [New South Wales] 的数据。\n",
      "\n",
      "--- 正在处理 [South Australia] ---\n",
      "✅ 已成功获取并处理完 [South Australia] 的数据。\n",
      "\n",
      "--- 正在处理 [Western Australia] ---\n",
      "✅ 已成功获取并处理完 [Western Australia] 的数据。\n",
      "\n",
      "--- 正在处理 [Australian Capital Territory] ---\n",
      "✅ 已成功获取并处理完 [Australian Capital Territory] 的数据。\n",
      "\n",
      "🎉 所有州的数据处理完毕。\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list to store each state's processed annual weather data\n",
    "annual_weather_data_list = []\n",
    "\n",
    "print(\"🚀 Starting to acquire and process state weather data using official client...\")\n",
    "\n",
    "# Iterate through each state\n",
    "for state, coords in capital_coords.items():\n",
    "    print(f\"\\n--- Processing [{state}] ---\")\n",
    "    \n",
    "    params = {\n",
    "        \"latitude\": coords[\"lat\"],\n",
    "        \"longitude\": coords[\"lon\"],\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": daily_vars_list,\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Use official client to call API\n",
    "        responses = openmeteo.weather_api(base_url, params=params)\n",
    "        response = responses[0]\n",
    "\n",
    "        # --- Parse returned data ---\n",
    "        daily = response.Daily()\n",
    "        \n",
    "        daily_precipitation_sum = daily.Variables(0).ValuesAsNumpy()\n",
    "        daily_temperature_2m_mean = daily.Variables(1).ValuesAsNumpy()\n",
    "        daily_shortwave_radiation_sum = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "        # --- Use official pd.date_range() method to create correct date index ---\n",
    "        daily_data = {\"date\": pd.date_range(\n",
    "            start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "            end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "            freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "            inclusive = \"left\"\n",
    "        )}\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        daily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
    "        daily_data[\"temperature_2m_mean\"] = daily_temperature_2m_mean\n",
    "        daily_data[\"shortwave_radiation_sum\"] = daily_shortwave_radiation_sum\n",
    "        \n",
    "        daily_df = pd.DataFrame(data=daily_data)\n",
    "        daily_df.set_index('date', inplace=True)\n",
    "        \n",
    "        # --- Annual aggregation logic (unchanged) ---\n",
    "        annual_agg_df = daily_df.resample('YE').agg({\n",
    "            'temperature_2m_mean': 'mean',\n",
    "            'precipitation_sum': 'sum',\n",
    "            'shortwave_radiation_sum': 'sum'\n",
    "        })\n",
    "        \n",
    "        annual_agg_df['state'] = state\n",
    "        annual_weather_data_list.append(annual_agg_df)\n",
    "        \n",
    "        print(f\"✅ Successfully acquired and processed [{state}] data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing [{state}]: {e}\")\n",
    "\n",
    "print(\"\\n🎉 All state data processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748ac46",
   "metadata": {},
   "source": [
    "### Step 7: Merge Data and Calculate National Averages\n",
    "\n",
    "Now we merge all state data from previous step into single large DataFrame. Then calculate averages across all states by year grouping to create \"National\" data, append to final DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cfefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成最终的天气数据集'weather_df'。\n"
     ]
    }
   ],
   "source": [
    "# Merge all states' annual weather data\n",
    "weather_df = pd.concat(annual_weather_data_list)\n",
    "\n",
    "# Extract year as regular column\n",
    "weather_df['year'] = weather_df.index.year\n",
    "weather_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calculate national annual averages\n",
    "# Group by year and average all numeric columns\n",
    "national_df = weather_df.groupby('year').mean(numeric_only=True).reset_index()\n",
    "national_df['state'] = 'National'\n",
    "\n",
    "# Append national data to main DataFrame\n",
    "weather_df = pd.concat([weather_df, national_df], ignore_index=True)\n",
    "\n",
    "# Rename columns for better readability\n",
    "weather_df.rename(columns={\n",
    "    'temperature_2m_mean': 'annual_mean_temp',\n",
    "    'precipitation_sum': 'annual_precip_sum',\n",
    "    'shortwave_radiation_sum': 'annual_radiation_sum'\n",
    "}, inplace=True)\n",
    "\n",
    "# Adjust column order\n",
    "weather_df = weather_df[['year', 'state', 'annual_mean_temp', 'annual_precip_sum', 'annual_radiation_sum']]\n",
    "\n",
    "print(\"Final weather dataset 'weather_df' generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc7413",
   "metadata": {},
   "source": [
    "### Step 8: Check Final Weather Data\n",
    "\n",
    "Finally, we check `weather_df` content and structure to ensure data is ready as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6dcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>annual_mean_temp</th>\n",
       "      <th>annual_precip_sum</th>\n",
       "      <th>annual_radiation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state, annual_mean_temp, annual_precip_sum, annual_radiation_sum]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_df[weather_df['state'] == \"Australian Capital Territory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d1141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>annual_mean_temp</th>\n",
       "      <th>annual_precip_sum</th>\n",
       "      <th>annual_radiation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>14.716250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>14.757990</td>\n",
       "      <td>615.799988</td>\n",
       "      <td>5848.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>14.526712</td>\n",
       "      <td>564.200012</td>\n",
       "      <td>5662.220215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>14.698013</td>\n",
       "      <td>432.399994</td>\n",
       "      <td>5789.760254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>14.443562</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>5895.100098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     state  annual_mean_temp  annual_precip_sum  annual_radiation_sum\n",
       "0  1999  Victoria         14.716250           0.000000             24.590000\n",
       "1  2000  Victoria         14.757990         615.799988           5848.040039\n",
       "2  2001  Victoria         14.526712         564.200012           5662.220215\n",
       "3  2002  Victoria         14.698013         432.399994           5789.760254\n",
       "4  2003  Victoria         14.443562         571.000000           5895.100098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows to check data format\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba59d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>annual_mean_temp</th>\n",
       "      <th>annual_precip_sum</th>\n",
       "      <th>annual_radiation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2020</td>\n",
       "      <td>National</td>\n",
       "      <td>16.554989</td>\n",
       "      <td>899.525024</td>\n",
       "      <td>6237.892578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2021</td>\n",
       "      <td>National</td>\n",
       "      <td>16.314037</td>\n",
       "      <td>849.174988</td>\n",
       "      <td>6297.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2022</td>\n",
       "      <td>National</td>\n",
       "      <td>16.460024</td>\n",
       "      <td>1122.150024</td>\n",
       "      <td>6253.627441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2023</td>\n",
       "      <td>National</td>\n",
       "      <td>16.750156</td>\n",
       "      <td>736.325012</td>\n",
       "      <td>6551.685059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2024</td>\n",
       "      <td>National</td>\n",
       "      <td>17.195477</td>\n",
       "      <td>731.349976</td>\n",
       "      <td>6567.745117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year     state  annual_mean_temp  annual_precip_sum  annual_radiation_sum\n",
       "125  2020  National         16.554989         899.525024           6237.892578\n",
       "126  2021  National         16.314037         849.174988           6297.140137\n",
       "127  2022  National         16.460024        1122.150024           6253.627441\n",
       "128  2023  National         16.750156         736.325012           6551.685059\n",
       "129  2024  National         17.195477         731.349976           6567.745117"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display last few rows to see calculated 'National' data\n",
    "weather_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d10c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130 entries, 0 to 129\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   year                  130 non-null    int32  \n",
      " 1   state                 130 non-null    object \n",
      " 2   annual_mean_temp      130 non-null    float32\n",
      " 3   annual_precip_sum     130 non-null    float32\n",
      " 4   annual_radiation_sum  130 non-null    float32\n",
      "dtypes: float32(3), int32(1), object(1)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data structure and types\n",
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf7dae",
   "metadata": {},
   "source": [
    "### Step 9: Data Cleaning and Final Confirmation\n",
    "\n",
    "Based on previous analysis, we need to perform two final cleaning tasks:\n",
    "1.  **Re-acquire Missing Data**: Due to API rate limits, `Australian Capital Territory` data wasn't acquired. We'll re-run Steps 6 and 7 to complete this data.\n",
    "2.  **Remove Anomalous Year**: Filter out erroneous 1999 record in data.\n",
    "\n",
    "After completing these steps, `weather_df` will be clean, complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已过滤掉年份为1999的数据。行数从 156 变为 150。\n",
      "\n",
      "✅ 所有州/地区的数据均已完整。\n",
      "\n",
      "--- 清理后的最终数据概览 ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150 entries, 1 to 155\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   year                  150 non-null    int32  \n",
      " 1   state                 150 non-null    object \n",
      " 2   annual_mean_temp      150 non-null    float32\n",
      " 3   annual_precip_sum     150 non-null    float32\n",
      " 4   annual_radiation_sum  150 non-null    float32\n",
      "dtypes: float32(3), int32(1), object(1)\n",
      "memory usage: 4.7+ KB\n",
      "\n",
      "--- 数据年份范围 ---\n",
      "从 2000 年到 2024 年\n"
     ]
    }
   ],
   "source": [
    "# Cleaning step 1: Filter out erroneous 1999 data\n",
    "# Keep only records with year >= 2000\n",
    "original_rows = len(weather_df)\n",
    "weather_df = weather_df[weather_df['year'] >= 2000].copy()\n",
    "\n",
    "print(f\"Filtered out 1999 data. Rows changed from {original_rows} to {len(weather_df)}.\")\n",
    "\n",
    "# Cleaning step 2: Check if all state data is complete\n",
    "# Normally should have 6 regions (5 states/territories + 1 National)\n",
    "if len(weather_df['state'].unique()) < 6:\n",
    "    print(\"\\nDetected missing state data (possibly due to API limits), recommend returning to re-run Steps 6 and 7.\")\n",
    "    print(\"Due to caching, re-running will only request previously failed parts and will be fast.\")\n",
    "else:\n",
    "    print(\"\\n✅ All state/territory data is complete.\")\n",
    "\n",
    "# Final confirmation\n",
    "print(\"\\n--- Final Data Overview After Cleaning ---\")\n",
    "weather_df.info()\n",
    "\n",
    "print(\"\\n--- Data Year Range ---\")\n",
    "print(f\"From {weather_df['year'].min()} to {weather_df['year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f155d0",
   "metadata": {},
   "source": [
    "### Step 10: Merge Main Data with Weather Data\n",
    "\n",
    "Now we merge `combined_df` (main data, 2000-2021) and `weather_df` (weather data, 2000-2024) into final dataset `final_df`.\n",
    "\n",
    "We use **Right Merge**, using weather data as base to retain all year records. This way, for 2022-2024 years that only have weather data, main data columns (like `index_value`) will automatically be filled with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da8372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 合并后数据 (头部) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>index_value</th>\n",
       "      <th>index_conf_low</th>\n",
       "      <th>index_conf_high</th>\n",
       "      <th>annual_mean_temp</th>\n",
       "      <th>annual_precip_sum</th>\n",
       "      <th>annual_radiation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.757990</td>\n",
       "      <td>615.799988</td>\n",
       "      <td>5848.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.851265</td>\n",
       "      <td>0.753910</td>\n",
       "      <td>0.954160</td>\n",
       "      <td>14.526712</td>\n",
       "      <td>564.200012</td>\n",
       "      <td>5662.220215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.738937</td>\n",
       "      <td>0.623807</td>\n",
       "      <td>0.873159</td>\n",
       "      <td>14.698013</td>\n",
       "      <td>432.399994</td>\n",
       "      <td>5789.760254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.728083</td>\n",
       "      <td>0.578651</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>14.443562</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>5895.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.647233</td>\n",
       "      <td>0.500643</td>\n",
       "      <td>0.853355</td>\n",
       "      <td>14.277344</td>\n",
       "      <td>621.200012</td>\n",
       "      <td>5806.970215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     state  index_value  index_conf_low  index_conf_high  \\\n",
       "0  2000  Victoria     1.000000        1.000000         1.000000   \n",
       "1  2001  Victoria     0.851265        0.753910         0.954160   \n",
       "2  2002  Victoria     0.738937        0.623807         0.873159   \n",
       "3  2003  Victoria     0.728083        0.578651         0.924713   \n",
       "4  2004  Victoria     0.647233        0.500643         0.853355   \n",
       "\n",
       "   annual_mean_temp  annual_precip_sum  annual_radiation_sum  \n",
       "0         14.757990         615.799988           5848.040039  \n",
       "1         14.526712         564.200012           5662.220215  \n",
       "2         14.698013         432.399994           5789.760254  \n",
       "3         14.443562         571.000000           5895.100098  \n",
       "4         14.277344         621.200012           5806.970215  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 合并后数据 (尾部) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>index_value</th>\n",
       "      <th>index_conf_low</th>\n",
       "      <th>index_conf_high</th>\n",
       "      <th>annual_mean_temp</th>\n",
       "      <th>annual_precip_sum</th>\n",
       "      <th>annual_radiation_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2020</td>\n",
       "      <td>National</td>\n",
       "      <td>0.305946</td>\n",
       "      <td>0.202542</td>\n",
       "      <td>0.489085</td>\n",
       "      <td>15.825681</td>\n",
       "      <td>890.140015</td>\n",
       "      <td>6209.967773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021</td>\n",
       "      <td>National</td>\n",
       "      <td>0.331837</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>0.582872</td>\n",
       "      <td>15.465296</td>\n",
       "      <td>883.320007</td>\n",
       "      <td>6234.124023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2022</td>\n",
       "      <td>National</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.654364</td>\n",
       "      <td>1109.099976</td>\n",
       "      <td>6152.215820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2023</td>\n",
       "      <td>National</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.014750</td>\n",
       "      <td>711.420044</td>\n",
       "      <td>6518.726074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2024</td>\n",
       "      <td>National</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.470160</td>\n",
       "      <td>703.160034</td>\n",
       "      <td>6553.233887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year     state  index_value  index_conf_low  index_conf_high  \\\n",
       "145  2020  National     0.305946        0.202542         0.489085   \n",
       "146  2021  National     0.331837        0.196334         0.582872   \n",
       "147  2022  National          NaN             NaN              NaN   \n",
       "148  2023  National          NaN             NaN              NaN   \n",
       "149  2024  National          NaN             NaN              NaN   \n",
       "\n",
       "     annual_mean_temp  annual_precip_sum  annual_radiation_sum  \n",
       "145         15.825681         890.140015           6209.967773  \n",
       "146         15.465296         883.320007           6234.124023  \n",
       "147         15.654364        1109.099976           6152.215820  \n",
       "148         16.014750         711.420044           6518.726074  \n",
       "149         16.470160         703.160034           6553.233887  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use 'year' and 'state' as common keys for right merge\n",
    "final_df = pd.merge(combined_df, weather_df, on=['year', 'state'], how='right')\n",
    "\n",
    "# Check head of merged dataset (should show complete 2000-2001 data)\n",
    "print(\"--- Merged Data (Head) ---\")\n",
    "display(final_df.head())\n",
    "\n",
    "# Check tail of merged dataset (should show 2024 data with index_value as NaN)\n",
    "print(\"\\n--- Merged Data (Tail) ---\")\n",
    "display(final_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831bf19",
   "metadata": {},
   "source": [
    "### Step 11: Store Final Merged Data\n",
    "\n",
    "We have successfully cleaned, aggregated, and merged original species index data with API-acquired weather data.\n",
    "\n",
    "Final step: save this `final_df` DataFrame containing complete 2000-2024 records as CSV file. This file will serve as input data for our next analysis phase (SARIMAX prediction model).\n",
    "\n",
    "Code will automatically check and create required subfolder (`01_data_wrangling/02_wrangled_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57851f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 数据已成功保存至: 02_wrangled_data\\Table14_TSX_Table_VIC_version3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define output folder and filename\n",
    "output_folder = os.path.join('02_wrangled_data')\n",
    "output_filename = 'Table14_TSX_Table_VIC_version3.csv'\n",
    "full_filepath = os.path.join(output_folder, output_filename)\n",
    "\n",
    "# Ensure output folder exists, create if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save final_df as CSV file\n",
    "# index=False prevents pandas from writing DataFrame index to file, keeping data clean\n",
    "final_df.to_csv(full_filepath, index=False)\n",
    "\n",
    "print(f\"🎉 Data successfully saved to: {full_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
