{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Species Care Guides — Data Pull Notebook\n",
    "\n",
    "This notebook fetches care-guide JSON from Perenual’s API and saves one file per species ID.\n",
    "It’s simple and polite to the API: single API key, light rate-limiting, retries on 429/5xx, and a safe stop when daily quota is likely hit. It’s also resume-friendly—existing files are skipped.  \n",
    "\n",
    "Before each time running, teammates can fetch from our github reporsitory first, then go through step 1 - 4, which means simply click \"Run All\" is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Configuration (range, output paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the API key, the ID range to fetch, basic rate-limit settings, and where to save the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ****912089, Range: 1~3000, Output dir: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\01_data_wrangling\\01_raw_data\\02_care_guide\n"
     ]
    }
   ],
   "source": [
    "# Put a single API key here\n",
    "API_KEY = \"sk-3ksU68b046f66e1f912089\"\n",
    "\n",
    "# Fetch range (start small when testing, then scale up)\n",
    "START_ID = 1\n",
    "END_ID   = 3000\n",
    "\n",
    "# Rate limiting & retry behavior\n",
    "SLEEP_BETWEEN = 1        # seconds to sleep after each request\n",
    "MAX_RETRIES   = 5\n",
    "BACKOFF_BASE  = 1.6\n",
    "\n",
    "# Output directory & filename pattern (pathlib adapts across OSes)\n",
    "from pathlib import Path\n",
    "OUT_DIR = Path(\"01_raw_data/02_care_guide\")\n",
    "FILENAME_PATTERN = \"plant_species_care_guide_{species_id}.json\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Key: ****{API_KEY[-6:]}, Range: {START_ID}~{END_ID}, Output dir: {OUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Some Small Helper Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal helpers to save JSON and build output file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "import requests\n",
    "\n",
    "def save_json(path: Path, data: Dict[str, Any]):\n",
    "    # Ensure the parent directory exists, then save UTF-8 JSON\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def build_filepath(species_id: int) -> Path:\n",
    "    # One JSON file per species_id\n",
    "    return OUT_DIR / FILENAME_PATTERN.format(species_id=species_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Fetch one species (with retries & safe-stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls the care-guide endpoint, handles 404s (placeholder), retries on temporary errors, and stops safely when rate limits/quota are inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_species_care_guide(species_id: int, api_key: str) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Success -> returns a JSON dict\n",
    "    404     -> returns {\"__missing__\": True, \"id\": species_id} (placeholder)\n",
    "    None    -> signals the main loop to stop (e.g., quota/IP limit, repeated 429, or x-ratelimit-remaining == 0)\n",
    "    \"\"\"\n",
    "    # API docs show the care-guide endpoint over HTTP\n",
    "    url = \"http://perenual.com/api/species-care-guide-list\"\n",
    "    attempt = 0\n",
    "    consecutive_429 = 0\n",
    "\n",
    "    while attempt <= MAX_RETRIES:\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                url,\n",
    "                params={\"species_id\": species_id, \"key\": api_key},\n",
    "                headers={\"accept\": \"application/json\"},\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            # Check remaining-quota hint if the server provides it\n",
    "            remaining = resp.headers.get(\"x-ratelimit-remaining\")\n",
    "            if remaining is not None:\n",
    "                try:\n",
    "                    if int(remaining) <= 0:\n",
    "                        print(f\"[ID {species_id}] x-ratelimit-remaining=0 → stopping safely (quota likely reached).\")\n",
    "                        return None\n",
    "                except ValueError:\n",
    "                    pass  # ignore if not an integer\n",
    "\n",
    "            if resp.status_code == 200:\n",
    "                return resp.json()\n",
    "\n",
    "            if resp.status_code == 404:\n",
    "                print(f\"[ID {species_id}] 404: this species may not have a care guide; saving a placeholder.\")\n",
    "                return {\"__missing__\": True, \"id\": species_id}\n",
    "\n",
    "            if resp.status_code == 429:\n",
    "                consecutive_429 += 1\n",
    "                if consecutive_429 >= 3:\n",
    "                    print(f\"[ID {species_id}] 429 occurred {consecutive_429} times in a row → stopping safely (rate/IP limit).\")\n",
    "                    return None\n",
    "                wait = (BACKOFF_BASE ** attempt) + 0.2 * attempt\n",
    "                print(f\"[ID {species_id}] 429 Too Many Requests — waiting {wait:.1f}s before retrying…\")\n",
    "                time.sleep(wait)\n",
    "                attempt += 1\n",
    "                continue\n",
    "\n",
    "            if resp.status_code in (500, 502, 503, 504):\n",
    "                wait = (BACKOFF_BASE ** attempt) + 0.2 * attempt\n",
    "                print(f\"[ID {species_id}] {resp.status_code} server error — waiting {wait:.1f}s then retrying…\")\n",
    "                time.sleep(wait)\n",
    "                attempt += 1\n",
    "                continue\n",
    "\n",
    "            # For other unexpected status codes, log a short snippet for context\n",
    "            print(f\"[ID {species_id}] HTTP {resp.status_code}: {resp.text[:200]}\")\n",
    "            return {\"__error_status__\": resp.status_code, \"id\": species_id}\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            wait = (BACKOFF_BASE ** attempt) + 0.2 * attempt\n",
    "            print(f\"[ID {species_id}] Network error ({type(e).__name__}): {e}. Waiting {wait:.1f}s then retrying…\")\n",
    "            time.sleep(wait)\n",
    "            attempt += 1\n",
    "\n",
    "    print(f\"[ID {species_id}] Retries exhausted. Skipping this one.\")\n",
    "    return {\"__error_retries_exhausted__\": True, \"id\": species_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Main loop (resume-friendly, skips existing files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops through the ID range, skips files that already exist, lightly sleeps between requests, and stops when the fetcher signals None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Care Guides:   0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ID 298] 429 Too Many Requests — waiting 1.0s before retrying…\n",
      "[ID 298] 429 Too Many Requests — waiting 1.8s before retrying…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Care Guides:  10%|▉         | 297/3000 [00:04<00:44, 61.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ID 298] 429 occurred 3 times in a row → stopping safely (rate/IP limit).\n",
      "Quota/rate-limit inferred → stopping safely.\n",
      "New downloads: 0, skipped (already exists): 297. Output dir: E:\\05_YZH_DS\\02_Monash_DS\\2025_S2_FIT5120_Industry_Experience_Studio_Project\\06_main_project\\03_github_submission\\03_github_submission\\2025-08-SDG13-Plant-X-Website\\01_data_wrangling\\01_raw_data\\02_care_guide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "downloaded = 0\n",
    "skipped = 0\n",
    "\n",
    "for species_id in tqdm(range(START_ID, END_ID + 1), desc=\"Downloading Care Guides\"):\n",
    "    fp = build_filepath(species_id)\n",
    "    if fp.exists():\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    data = fetch_species_care_guide(species_id, API_KEY)\n",
    "    if data is None:\n",
    "        print(\"Quota/rate-limit inferred → stopping safely.\")\n",
    "        break\n",
    "\n",
    "    save_json(fp, data)\n",
    "    downloaded += 1\n",
    "    # Small random jitter helps avoid synchronized spikes\n",
    "    time.sleep(SLEEP_BETWEEN + random.uniform(0.0, 0.6))\n",
    "\n",
    "print(f\"New downloads: {downloaded}, skipped (already exists): {skipped}. Output dir: {OUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 (Optional) - Pack and download as a zip (for Colab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running on Colab, zip the folder and download it locally. On a local machine, just use your file manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only needed on Google Colab; skip on local environments\n",
    "# import shutil\n",
    "# from google.colab import files\n",
    "#\n",
    "# shutil.make_archive(\"02_species_care_guide\", 'zip', \"01_raw_data/02_care_guide\")\n",
    "# files.download(\"02_species_care_guide.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
